{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOd/mHL+6ZWevdCwbOoPbPY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IyadSultan/low-coding-AI/blob/main/04_tools_and_agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 04 Tools and Agents\n",
        "\n",
        "A very important link https://python.langchain.com/docs/integrations/tools/\n",
        "\n",
        "Below is a step-by-step tutorial demonstrating how to combine OpenAI Function Calling and the LangChain ecosystem for building “tools and agents.” This tutorial focuses first on the foundations—how to call functions, parse outputs, and chain calls. It then culminates in a more advanced example: reading a medical note, summarizing it, finding the best PubMed search results, retrieving references, and constructing a recommendation letter.\n",
        "All code blocks are designed to run in Google Colab (or similar Python environments). Some blocks are examples to illustrate concepts (you may not need to run them all, but they’re helpful references). If you plan to save your results, be aware that Colab resets often, so consider downloading your notebook or saving to GitHub."
      ],
      "metadata": {
        "id": "3cqdUS6qATvO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Environment Setup**"
      ],
      "metadata": {
        "id": "8u-329PrBJma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import openai\n",
        "from google.colab import userdata\n",
        "OPENAI_API_KEY=userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "uDthrjp3AUee"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Quick Start with OpenAI Function Calling**\n",
        "\n",
        "Let’s begin by showing the essential structure for function calling with the OpenAI ChatCompletion endpoints.\n",
        "\n"
      ],
      "metadata": {
        "id": "kcMdaasVAVhZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BpKRhnsFAVbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Introducing LangChain’s “Runnable” and “Chain” Utilities**\n",
        "\n",
        "3.1 Simple “Runnable” Pipeline\n",
        "LangChain 0.0.305+ introduced the Runnable classes, which let you chain various pieces (prompts, LLMs, output parsers) in a pipeline style.\n"
      ],
      "metadata": {
        "id": "GXlivhSIAVXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "# from langchain_core.output_parsers import StrOutputParser  # Alternative import if needed\n",
        "import os\n",
        "\n",
        "# Set your OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Build a simple chain: Prompt -> LLM -> OutputParser\n",
        "prompt = ChatPromptTemplate.from_template(\"tell me a short joke about {topic}\")\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)  # Specify model name\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# Create and run the chain\n",
        "chain = prompt | model | output_parser\n",
        "\n",
        "try:\n",
        "    result = chain.invoke({\"topic\": \"bears\"})\n",
        "    print(result)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFareswTAVR4",
        "outputId": "e4c012a3-b928-4dca-d116-7d8107ba9bf6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why do bears have hairy coats?\n",
            "\n",
            "Because they look silly in sweaters!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a simple chain: Prompt -> LLM -> OutputParser\n",
        "prompt = ChatPromptTemplate.from_template(\"How is the weather in {city}\")\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=1)  # Specify model name\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# Create and run the chain\n",
        "chain = prompt | model | output_parser\n",
        "\n",
        "result = chain.invoke({\"city\": \"Amman\"})\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72Nye3SuDJzh",
        "outputId": "902b8d84-0449-4f1e-f81d-4b5ce78bd223"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I don't have real-time weather data, but you can easily check the current weather in Amman by using a weather website or a weather app on your smartphone. Typically, the weather in Amman varies by season, with hot summers and mild winters. If you need information about the typical weather for a specific time of year, feel free to ask!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weather_dic={\n",
        "\"Amman\": \"Mild spring weather, around 20°C (68°F), partly cloudy\",\n",
        "\"Amsterdam\": \"Cool spring conditions, around 12°C (54°F), likely overcast with chance of rain\",\n",
        "\"Auckland\": \"Autumn season, mild temperatures around 18°C (64°F), partly cloudy with occasional showers\",\n",
        "\"Athens\": \"Pleasant spring weather, around 22°C (72°F), mostly sunny\",\n",
        "\"Adelaide\": \"Autumn weather, around 21°C (70°F), clear skies\"\n",
        "}"
      ],
      "metadata": {
        "id": "epZlT0kaN43V"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write a function that uses this dictionary to return the weather in any specified city\n",
        "\n",
        "\n",
        "def get_weather(city):\n",
        "  \"\"\"\n",
        "  Returns the weather in the specified city using the weather_dic dictionary.\n",
        "\n",
        "  Args:\n",
        "      city: The name of the city.\n",
        "\n",
        "  Returns:\n",
        "      The weather description for the city, or None if the city is not found.\n",
        "  \"\"\"\n",
        "  return weather_dic.get(city)"
      ],
      "metadata": {
        "id": "nkK8BQkqN4ps"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_weather(\"Amman\")"
      ],
      "metadata": {
        "id": "1unfgRVBN4L6"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define the function as a tool\n",
        "functions = [\n",
        "    {\n",
        "        \"name\": \"get_weather\",\n",
        "        \"description\": \"Get the current weather for a given city.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"city\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The name of the city to get weather for.\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"city\"]\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "\n",
        "def chat_with_gpt(user_message):\n",
        "    \"\"\"\n",
        "    Sends a message to the GPT model and allows it to use the get_weather function when needed.\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",  # Correct model name\n",
        "        messages=[{\"role\": \"user\", \"content\": user_message}],\n",
        "        functions=functions,\n",
        "        function_call=\"auto\"  # Enable function calling\n",
        "    )\n",
        "\n",
        "\n",
        "    message = response.choices[0].message\n",
        "\n",
        "\n",
        "    # Handle function calls if present\n",
        "    if message.function_call:\n",
        "        function_name = message.function_call.name\n",
        "        function_args = json.loads(message.function_call.arguments)\n",
        "\n",
        "        if function_name == \"get_weather\":\n",
        "            function_response = get_weather(function_args[\"city\"])\n",
        "\n",
        "            # Send the function response back to GPT\n",
        "            final_response = client.chat.completions.create(\n",
        "                model=\"gpt-4-turbo-preview\",\n",
        "                messages=[\n",
        "                    {\"role\": \"user\", \"content\": user_message},\n",
        "                    message,\n",
        "                    {\n",
        "                        \"role\": \"function\",\n",
        "                        \"name\": \"get_weather\",\n",
        "                        \"content\": function_response\n",
        "                    }\n",
        "                ]\n",
        "            )\n",
        "            return final_response.choices[0].message.content\n",
        "\n",
        "    return message.content\n",
        "\n",
        "\n",
        "# Example Usage\n",
        "user_input = \"What's the weather like in Amman today?\"\n",
        "print(chat_with_gpt(user_input))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cENiFHAKO5Rk",
        "outputId": "f12d1a97-4bea-4973-9f7b-26f8e5e8433e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The weather in Amman today is mild spring weather, with temperatures around 20°C (68°F) and it's partly cloudy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yDDaYHl6AVNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
        "from typing import Optional\n",
        "from datetime import datetime\n",
        "\n",
        "# Create a mock weather database\n",
        "weather_db = {\n",
        "    \"SFO\": {\n",
        "        \"city\": \"San Francisco\",\n",
        "        \"temperature\": 65,\n",
        "        \"conditions\": \"Foggy\",\n",
        "        \"humidity\": 75,\n",
        "        \"wind_speed\": 12,\n",
        "        \"last_updated\": \"2025-01-29 08:00:00\"\n",
        "    },\n",
        "    \"JFK\": {\n",
        "        \"city\": \"New York\",\n",
        "        \"temperature\": 45,\n",
        "        \"conditions\": \"Partly Cloudy\",\n",
        "        \"humidity\": 60,\n",
        "        \"wind_speed\": 15,\n",
        "        \"last_updated\": \"2025-01-29 08:00:00\"\n",
        "    },\n",
        "    \"LAX\": {\n",
        "        \"city\": \"Los Angeles\",\n",
        "        \"temperature\": 75,\n",
        "        \"conditions\": \"Sunny\",\n",
        "        \"humidity\": 50,\n",
        "        \"wind_speed\": 8,\n",
        "        \"last_updated\": \"2025-01-29 08:00:00\"\n",
        "    },\n",
        "    \"ORD\": {\n",
        "        \"city\": \"Chicago\",\n",
        "        \"temperature\": 32,\n",
        "        \"conditions\": \"Snow\",\n",
        "        \"humidity\": 80,\n",
        "        \"wind_speed\": 20,\n",
        "        \"last_updated\": \"2025-01-29 08:00:00\"\n",
        "    },\n",
        "    \"QAA\": {\n",
        "        \"city\": \"Amman\",\n",
        "        \"temperature\": 82,\n",
        "        \"conditions\": \"Thunderstorms\",\n",
        "        \"humidity\": 85,\n",
        "        \"wind_speed\": 18,\n",
        "        \"last_updated\": \"2025-01-29 08:00:00\"\n",
        "    }\n",
        "}\n",
        "\n",
        "class WeatherSearch(BaseModel):\n",
        "    \"\"\"Call this with an airport code to get the weather at that airport\"\"\"\n",
        "    airport_code: str = Field(description=\"airport code to get weather for\")\n",
        "\n",
        "    def get_weather(self) -> Optional[dict]:\n",
        "        \"\"\"Get weather for the specified airport\"\"\"\n",
        "        try:\n",
        "            if self.airport_code not in weather_db:\n",
        "                return {\n",
        "                    \"error\": f\"No weather data available for {self.airport_code}\",\n",
        "                    \"available_airports\": list(weather_db.keys())\n",
        "                }\n",
        "\n",
        "            weather_data = weather_db[self.airport_code]\n",
        "            return {\n",
        "                \"airport\": self.airport_code,\n",
        "                \"city\": weather_data[\"city\"],\n",
        "                \"temperature\": f\"{weather_data['temperature']}°F\",\n",
        "                \"conditions\": weather_data[\"conditions\"],\n",
        "                \"humidity\": f\"{weather_data['humidity']}%\",\n",
        "                \"wind_speed\": f\"{weather_data['wind_speed']} mph\",\n",
        "                \"last_updated\": weather_data[\"last_updated\"]\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\"error\": str(e)}\n",
        "\n",
        "weather_function = convert_pydantic_to_openai_function(WeatherSearch)\n",
        "\n",
        "# Test the function with different airports\n",
        "test_codes = [\"QAA\", \"SFO\", \"JFK\", \"LAX\", \"ORD\", \"DFW\"]  # DFW isn't in our database\n",
        "\n",
        "for code in test_codes:\n",
        "    try:\n",
        "        search = WeatherSearch(airport_code=code)\n",
        "        weather_data = search.get_weather()\n",
        "        print(f\"\\nWeather lookup for {code}:\")\n",
        "        print(weather_data)\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError processing {code}: {e}\")\n",
        "\n",
        "# Print the function definition\n",
        "print(\"\\nFunction definition:\")\n",
        "print(weather_function)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGkHA-6xAVHH",
        "outputId": "5c535de6-5552-4084-999e-ca9aaa84acf0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Weather lookup for QAA:\n",
            "{'airport': 'QAA', 'city': 'Amman', 'temperature': '82°F', 'conditions': 'Thunderstorms', 'humidity': '85%', 'wind_speed': '18 mph', 'last_updated': '2025-01-29 08:00:00'}\n",
            "\n",
            "Weather lookup for SFO:\n",
            "{'airport': 'SFO', 'city': 'San Francisco', 'temperature': '65°F', 'conditions': 'Foggy', 'humidity': '75%', 'wind_speed': '12 mph', 'last_updated': '2025-01-29 08:00:00'}\n",
            "\n",
            "Weather lookup for JFK:\n",
            "{'airport': 'JFK', 'city': 'New York', 'temperature': '45°F', 'conditions': 'Partly Cloudy', 'humidity': '60%', 'wind_speed': '15 mph', 'last_updated': '2025-01-29 08:00:00'}\n",
            "\n",
            "Weather lookup for LAX:\n",
            "{'airport': 'LAX', 'city': 'Los Angeles', 'temperature': '75°F', 'conditions': 'Sunny', 'humidity': '50%', 'wind_speed': '8 mph', 'last_updated': '2025-01-29 08:00:00'}\n",
            "\n",
            "Weather lookup for ORD:\n",
            "{'airport': 'ORD', 'city': 'Chicago', 'temperature': '32°F', 'conditions': 'Snow', 'humidity': '80%', 'wind_speed': '20 mph', 'last_updated': '2025-01-29 08:00:00'}\n",
            "\n",
            "Weather lookup for DFW:\n",
            "{'error': 'No weather data available for DFW', 'available_airports': ['SFO', 'JFK', 'LAX', 'ORD', 'QAA']}\n",
            "\n",
            "Function definition:\n",
            "{'name': 'WeatherSearch', 'description': 'Call this with an airport code to get the weather at that airport', 'parameters': {'properties': {'airport_code': {'description': 'airport code to get weather for', 'type': 'string'}}, 'required': ['airport_code'], 'type': 'object'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-fa59267eb90d>:76: LangChainDeprecationWarning: The function `_convert_pydantic_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 1.0. Use :meth:`~langchain_core.utils.function_calling.convert_to_openai_function()` instead.\n",
            "  weather_function = convert_pydantic_to_openai_function(WeatherSearch)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(weather_function)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_suIDNvQYvq",
        "outputId": "9951191f-a9a3-4153-fecc-02f15866d218"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': 'WeatherSearch', 'description': 'Call this with an airport code to get the weather at that airport', 'parameters': {'properties': {'airport_code': {'description': 'airport code to get weather for', 'type': 'string'}}, 'required': ['airport_code'], 'type': 'object'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.2 Binding Functions to a Chat Model**"
      ],
      "metadata": {
        "id": "gDqT70jbAVBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize the ChatOpenAI model with the function\n",
        "OPENAI_API_KEY=userdata.get('OPENAI_API_KEY')\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
        "model_with_function = model.bind(functions=[weather_function])\n",
        "chain=model_with_function|output_parser\n",
        "\n",
        "\n",
        "\n",
        "# Test queries\n",
        "queries = [\n",
        "    \"What's the weather in SFO?\",\n",
        "    \"Tell me the weather at Amman?\",\n",
        "    \"What's the temperature in Los Angeles (LAX)?\",\n",
        "    \"What's the weather like in DFW?\" # This should show error as it's not in our database\n",
        "]\n",
        "\n",
        "for query in queries:\n",
        "    print(f\"\\nQuery: {query}\")\n",
        "    response = chain.invoke(query)\n",
        "    print(f\"Response: {response}\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OZ1oF88AU6F",
        "outputId": "8a738c4a-f342-4246-86ac-5de192b59f66"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query: What's the weather in SFO?\n",
            "Response: \n",
            "\n",
            "Query: Tell me the weather at Amman?\n",
            "Response: \n",
            "\n",
            "Query: What's the temperature in Los Angeles (LAX)?\n",
            "Response: \n",
            "\n",
            "Query: What's the weather like in DFW?\n",
            "Response: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.3 Force-Calling a Function**\n",
        "You can also force the model to always call a particular function:\n"
      ],
      "metadata": {
        "id": "lG30UwSfAUu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_with_function = model.bind(\n",
        "    functions=[weather_function],\n",
        "    function_call={\"name\": \"WeatherSearch\"}  # Force the model to always use this function\n",
        ")\n",
        "output_parser = StrOutputParser()\n",
        "chain=model_with_function|output_parser\n",
        "# print(model_with_function.invoke(\"What's the weather in SFO?\"))\n",
        "chain.invoke(\"What's the weather in SFO?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "FeSt0gK1ATqc",
        "outputId": "bf0fffed-be57-47cf-9b55-77d6f6a47680"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Tools and Agents in LangChain**\n",
        "\n",
        "In LangChain, “tools” are simply Python callables (functions) that can be exposed to an LLM. Agents decide which tool to call and when to call it.\n",
        "5.1 Defining Tools\n",
        "LangChain supplies a @tool decorator for convenience. Example:\n",
        "from langchain.agents import tool\n"
      ],
      "metadata": {
        "id": "Y_v4g5Q7ATlY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install Wikipedia\n",
        "from langchain.agents import tool\n",
        "import wikipedia\n",
        "\n",
        "@tool\n",
        "def search_wikipedia(query: str) -> str:\n",
        "    \"\"\"Search Wikipedia and get page summaries.\"\"\"\n",
        "    try:\n",
        "        # Get search results\n",
        "        page = wikipedia.page(query, auto_suggest=False)\n",
        "        return f\"Title: {page.title}\\nSummary: {page.summary}\"\n",
        "    except:\n",
        "        try:\n",
        "            # If direct search fails, try getting the first result from search\n",
        "            results = wikipedia.search(query, results=1)\n",
        "            if results:\n",
        "                page = wikipedia.page(results[0], auto_suggest=False)\n",
        "                return f\"Title: {page.title}\\nSummary: {page.summary}\"\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    return \"No Wikipedia article found.\"\n",
        "\n",
        "print(search_wikipedia(\"Python programming\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGANDA8mAThf",
        "outputId": "ce28ca06-6afd-4400-d77e-1c7771a4fdd9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-ea34a843b4b3>:24: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  print(search_wikipedia(\"Python programming\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: Python (programming language)\n",
            "Summary: Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code readability with the use of significant indentation.\n",
            "Python is dynamically type-checked and garbage-collected. It supports multiple programming paradigms, including structured (particularly procedural), object-oriented and functional programming. It is often described as a \"batteries included\" language due to its comprehensive standard library.\n",
            "Guido van Rossum began working on Python in the late 1980s as a successor to the ABC programming language and first released it in 1991 as Python 0.9.0. Python 2.0 was released in 2000. Python 3.0, released in 2008, was a major revision not completely backward-compatible with earlier versions. Python 2.7.18, released in 2020, was the last release of Python 2.\n",
            "Python consistently ranks as one of the most popular programming languages, and has gained widespread use in the machine learning community.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.2 Converting Tools to OpenAI Functions**"
      ],
      "metadata": {
        "id": "us0BtMaSATd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools.render import format_tool_to_openai_function\n",
        "\n",
        "formatted_tool = format_tool_to_openai_function(search_wikipedia)\n",
        "print(formatted_tool)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqSFWHX0ATYK",
        "outputId": "32f311f3-fd5d-481a-8a67-3d5f43b42fa7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': 'search_wikipedia', 'description': 'Search Wikipedia and get page summaries.', 'parameters': {'properties': {'query': {'type': 'string'}}, 'required': ['query'], 'type': 'object'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-1f6b32bd8305>:3: LangChainDeprecationWarning: The function `_format_tool_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 1.0. Use :meth:`~langchain_core.utils.function_calling.convert_to_openai_function()` instead.\n",
            "  formatted_tool = format_tool_to_openai_function(search_wikipedia)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.3 A Simple Routing Example**\n",
        "If you pass multiple tools, the LLM will pick which function to call or produce a direct textual response. For instance:\n",
        "\n"
      ],
      "metadata": {
        "id": "iMQCFU6HATR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
        "\n",
        "\n",
        "functions = [formatted_tool, weather_function]  # Suppose we have two\n",
        "\n",
        "\n",
        "model = ChatOpenAI(temperature=0).bind(functions=functions)\n",
        "chain=model|output_parser\n",
        "chain.invoke(\"What's the weather in SFO?\")\n",
        "# result = model.invoke(\"What is the weather in Boston right now?\")\n",
        "# print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Tf6OM8HHATL8",
        "outputId": "7016e8e4-0f20-4f4e-97c5-5348c6076165"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install xmltodict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiwPHM2fTv1v",
        "outputId": "8c75b649-a1fa-455f-9376-3836d0678baa"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.11/dist-packages (0.14.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.pubmed.tool import PubmedQueryRun\n",
        "\n",
        "# Initialize the PubMed query tool\n",
        "pubmed_tool = PubmedQueryRun()\n",
        "\n",
        "# Define the search query for lung cancer\n",
        "query = \"lung cancer\"\n",
        "\n",
        "# Run the query to get results\n",
        "results = pubmed_tool.invoke(query)\n",
        "\n",
        "# Extract and display 10 abstracts from the results\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lowd_KtETvkv",
        "outputId": "3f59d12e-3c1d-4764-d115-0346f017689b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Too Many Requests, waiting for 0.20 seconds...\n",
            "Too Many Requests, waiting for 0.40 seconds...\n",
            "Published: --\n",
            "Title: Retraction: Down-regulation of lncRNA XIST inhibits cell proliferation via regulating miR-744/RING1 axis in non-small cell lung cancer.\n",
            "Copyright Information: \n",
            "Summary::\n",
            "No abstract available\n",
            "\n",
            "Published: 2025-01-02\n",
            "Title: Sensitivity to Environmental Stress and Adversity and Lung Cancer.\n",
            "Copyright Information: \n",
            "Summary::\n",
            "IMPORTANCE: Sensitivity to environmental stress and adversity may influence lung cancer risk, highlighting a critical link between psychosocial factors and cancer etiology.\n",
            "OBJECTIVE: To evaluate whether genetically estimated sensitivity to environmental stress and adversity is associated with lung cancer risk.\n",
            "DESIGN, SETTING, AND PARTICIPANTS: Data were obtained from a genome-wide association study identifying 37 independent genetic variants strongly associated with sensitivity to environmental stress and adversity and a cross-ancestry genome-wide meta-analysis from the International Lung Cancer Consortium. Data were extracted between October 2023 and January 2024 and analyzed between February 2024 and June 2024.\n",
            "EXPOSURES: Genetically estimated sensitivity to environmental stress and adversity.\n",
            "MAIN OUTCOMES AND MEASURES: The main outcome was lung cancer risk, and odds ratios and 95% CIs were used to assess the association between sensitivity to environmental stress and adversity with lung cancer risk. This genetic association study used a 2-sample Mendelian randomization (MR) to estimate the association between genetically estimated sensitivity to environmental stress and adversity and lung cancer risk across different histologic types.\n",
            "RESULTS: Using data from 351 827 individuals from the UK Biobank and a cross-ancestry genome-wide analysis of 61 047 lung cancer cases and 947 237 controls from the International Lung Cancer Consortium, sensitivity to environmental stress and adversity was significantly associated with an increased risk of lung cancer among individuals of European ancestry (OR, 1.49; 95% CI, 1.13-1.98; P = .0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.retrievers import PubMedRetriever\n",
        "retriever = PubMedRetriever()\n",
        "result=retriever.invoke('Lung Cancer')\n",
        "print(len(result))\n",
        "# print(result[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxSC8P_MTvKA",
        "outputId": "d2397e10-1a9c-4808-f807-baad5224ce73"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Too Many Requests, waiting for 0.20 seconds...\n",
            "Too Many Requests, waiting for 0.40 seconds...\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_google_community\n",
        "\n",
        "from langchain_core.tools import Tool\n",
        "from langchain_google_community import GoogleSearchAPIWrapper\n",
        "\n",
        "search = GoogleSearchAPIWrapper()\n",
        "\n",
        "tool = Tool(\n",
        "    name=\"google_search\",\n",
        "    description=\"Search Google for recent results.\",\n",
        "    func=search.run,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JdXmYY7dTvBB",
        "outputId": "075a591f-0bf4-443d-af57-3c140ff0b632"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_google_community\n",
            "  Downloading langchain_google_community-2.0.4-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=2.17.1 in /usr/local/lib/python3.11/dist-packages (from langchain_google_community) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client<3.0.0,>=2.122.0 in /usr/local/lib/python3.11/dist-packages (from langchain_google_community) (2.155.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from langchain_google_community) (2.4.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.62.0 in /usr/local/lib/python3.11/dist-packages (from langchain_google_community) (1.70.0)\n",
            "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain_google_community) (0.3.16)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain_google_community) (0.3.32)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=2.17.1->langchain_google_community) (1.66.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=2.17.1->langchain_google_community) (4.25.6)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=2.17.1->langchain_google_community) (1.25.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=2.17.1->langchain_google_community) (2.27.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=2.17.1->langchain_google_community) (2.32.3)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.122.0->langchain_google_community) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.122.0->langchain_google_community) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.122.0->langchain_google_community) (4.1.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_google_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_google_community) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_google_community) (3.11.11)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_google_community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_google_community) (0.4.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.16 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_google_community) (0.3.16)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_google_community) (0.3.1)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_google_community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_google_community) (2.7.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_google_community) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.3.0->langchain_google_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.3.0->langchain_google_community) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.3.0->langchain_google_community) (2.10.6)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.3.0->langchain_google_community) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_google_community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_google_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_google_community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_google_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_google_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_google_community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_google_community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_google_community) (3.26.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_google_community) (0.9.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=2.17.1->langchain_google_community) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=2.17.1->langchain_google_community) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=2.17.1->langchain_google_community) (4.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client<3.0.0,>=2.122.0->langchain_google_community) (3.2.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain_google_community) (3.0.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.16->langchain-community<0.4.0,>=0.3.0->langchain_google_community) (0.3.5)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_google_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_google_community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_google_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_google_community) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain_google_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain_google_community) (2.27.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain_google_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core<3.0.0,>=2.17.1->langchain_google_community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core<3.0.0,>=2.17.1->langchain_google_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core<3.0.0,>=2.17.1->langchain_google_community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core<3.0.0,>=2.17.1->langchain_google_community) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community<0.4.0,>=0.3.0->langchain_google_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_google_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_google_community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_google_community) (0.14.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=2.17.1->langchain_google_community) (0.6.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_google_community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_google_community) (1.3.1)\n",
            "Downloading langchain_google_community-2.0.4-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain_google_community\n",
            "Successfully installed langchain_google_community-2.0.4\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValidationError",
          "evalue": "1 validation error for GoogleSearchAPIWrapper\n  Value error, Did not find google_api_key, please add an environment variable `GOOGLE_API_KEY` which contains it, or pass `google_api_key` as a named parameter. [type=value_error, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-1439abfd2d26>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_google_community\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogleSearchAPIWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msearch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogleSearchAPIWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m tool = Tool(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;31m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mvalidated_self\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pydantic_validator__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalidated_self\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             warnings.warn(\n",
            "\u001b[0;31mValidationError\u001b[0m: 1 validation error for GoogleSearchAPIWrapper\n  Value error, Did not find google_api_key, please add an environment variable `GOOGLE_API_KEY` which contains it, or pass `google_api_key` as a named parameter. [type=value_error, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lxywz5XXTuvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Building a Conversational Agent with Memory**\n",
        "Let’s combine:\n",
        "Tools for weather, Wikipedia.\n",
        "A Chat model that can call them as needed.\n",
        "Conversation memory so the agent can remember earlier turns.\n"
      ],
      "metadata": {
        "id": "U97j2AT7ATHg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install langchain_community\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
        "from langchain.agents import AgentExecutor\n",
        "from langchain.agents import tool\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.tools.render import format_tool_to_openai_function\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "import wikipedia\n",
        "\n",
        "\n",
        "@tool\n",
        "def search_wikipedia(query: str) -> str:\n",
        "    \"\"\"Search Wikipedia and get page summaries.\"\"\"\n",
        "    try:\n",
        "        page = wikipedia.page(query, auto_suggest=False)\n",
        "        return f\"Title: {page.title}\\nSummary: {page.summary}\"\n",
        "    except:\n",
        "        try:\n",
        "            results = wikipedia.search(query, results=1)\n",
        "            if results:\n",
        "                page = wikipedia.page(results[0], auto_suggest=False)\n",
        "                return f\"Title: {page.title}\\nSummary: {page.summary}\"\n",
        "        except:\n",
        "            pass\n",
        "    return \"No Wikipedia article found.\"\n",
        "\n",
        "@tool\n",
        "def get_current_temperature(location: str) -> str:\n",
        "    \"\"\"Get the current temperature for a location.\"\"\"\n",
        "    return f\"It is 70F in {location}\"\n",
        "\n",
        "# Helper function to format intermediate steps\n",
        "def format_to_openai_functions(intermediate_steps):\n",
        "    \"\"\"Format intermediate steps to OpenAI function messages.\"\"\"\n",
        "    messages = []\n",
        "    for action, observation in intermediate_steps:\n",
        "        messages.append({\n",
        "            \"tool\": action.tool,\n",
        "            \"tool_input\": action.tool_input,\n",
        "            \"observation\": observation\n",
        "        })\n",
        "    return messages\n",
        "\n",
        "# Format tools\n",
        "tools = [search_wikipedia, get_current_temperature]\n",
        "functions = [format_tool_to_openai_function(t) for t in tools]\n",
        "\n",
        "# Initialize model with functions\n",
        "model = ChatOpenAI(temperature=0).bind(functions=functions)\n",
        "\n",
        "# Create prompt template\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant. Remember information about the user.\"),\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "])\n",
        "\n",
        "# Create the chain with initial empty intermediate steps\n",
        "chain = RunnablePassthrough.assign(\n",
        "    chat_history=lambda x: x.get(\"chat_history\", []),\n",
        "    intermediate_steps=lambda x: x.get(\"intermediate_steps\", []),\n",
        "    agent_scratchpad=lambda x: format_to_openai_functions(x[\"intermediate_steps\"])\n",
        ") | prompt | model | OpenAIFunctionsAgentOutputParser()\n",
        "\n",
        "# Initialize memory\n",
        "memory = ConversationBufferMemory(return_messages=True, memory_key=\"chat_history\")\n",
        "\n",
        "# Create agent executor\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=chain,\n",
        "    tools=tools,\n",
        "    verbose=True,\n",
        "    memory=memory\n",
        ")\n",
        "\n",
        "# Test the agent\n",
        "try:\n",
        "    # First interaction\n",
        "    response1 = agent_executor.invoke({\"input\": \"My name is Bob.\"})\n",
        "    print(\"Response 1:\", response1)\n",
        "\n",
        "    # Second interaction\n",
        "    response2 = agent_executor.invoke({\"input\": \"What's my name?\"})\n",
        "    print(\"Response 2:\", response2)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {str(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dlo2l_tATCD",
        "outputId": "bb81bc22-2033-44e2-dce0-70dd7580a328"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mNice to meet you, Bob! How can I assist you today?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Response 1: {'input': 'My name is Bob.', 'chat_history': [HumanMessage(content='My name is Bob.', additional_kwargs={}, response_metadata={}), AIMessage(content='Nice to meet you, Bob! How can I assist you today?', additional_kwargs={}, response_metadata={})], 'output': 'Nice to meet you, Bob! How can I assist you today?'}\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mYour name is Bob.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Response 2: {'input': \"What's my name?\", 'chat_history': [HumanMessage(content='My name is Bob.', additional_kwargs={}, response_metadata={}), AIMessage(content='Nice to meet you, Bob! How can I assist you today?', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Bob.', additional_kwargs={}, response_metadata={})], 'output': 'Your name is Bob.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "feUFMxOdAS88"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nFruIB7hAS4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zbOSjGc-ASzt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7lMpWJFcASuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QV-c18yIASo5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OuRW1dCCASkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "h8Ux2BwUASe3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qXP2oaMqASZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "y7uGMzcYASTc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KMCLuPIDASNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FyBaTJGHASHw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HR6LkfEqASBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pmNwXUt7AR8I"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "erK1VHByAR1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_dMjK9FuARu_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-X7gPKAZARo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kVqblyorARiw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FebotAV0ARb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "R9tTd5BSARVA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yuea4ju_AROO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1ZZL-FbnARH7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NlqCwKIVARBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZgrpBoA2AQ7g"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aJMr61ZDAQ0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "88gFjgcWAQt-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OuM4zeNfAQm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "78vl6O7kAQhV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fWaX02h-AQZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "k6yEextnAQTz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "12MbXHloAQNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9mzRIOpkAQG2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rK_TFACAAP_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pC-Sg9HUAP44"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kc6AqwYNAPxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "htYg7vPKAPps"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6LPPaXP1APjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QqvcCSOcAPbn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C_a2slBuAPVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gFCjIpJpAPNo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dxK_Eak6APGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZOkzLl_nAO-4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ik1rZXZ6AO4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "V5hDmSRzAOw7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BY-Cy6mBAOmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3mhyD9mJAOfu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1OZJdTDWAOYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ynAyNA5xAOQH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}